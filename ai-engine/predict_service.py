import json
import pandas as pd
from kafka import KafkaConsumer, KafkaProducer
from sklearn.linear_model import LinearRegression
import numpy as np
import datetime
import sys

# Windowsã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®æ–‡å­—åŒ–ã‘å¯¾ç­–ï¼ˆUTF-8å¼·åˆ¶ï¼‰
sys.stdout.reconfigure(encoding='utf-8')

# Kafkaè¨­å®š
KAFKA_TOPIC_INPUT = "scouter.score.input"
KAFKA_TOPIC_OUTPUT = "scouter.prediction.result"
KAFKA_BROKER = "localhost:9092"

# --- äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯æœ¬ä½“ (predict_weekly_conditioné–¢æ•°ã¨ã—ã¦å®šç¾©) ---
def predict_weekly_condition(df_input):
    """éå»ã®ã‚¹ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€æ¥é€±ã®ä½“èª¿ã‚’äºˆæ¸¬ã™ã‚‹"""
    
    # ä»¥å‰ã®äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã“ã“ã«ç§»æ¤ï¼ˆä¸­èº«ã¯å¤‰æ›´ãªã—ï¼‰
    if len(df_input) < 2: return []

    # â˜…ä¿®æ­£ç®‡æ‰€:
    # Javaå´ã§ targetDate ãŒ 'YYYY-MM-DD' ã®æ–‡å­—åˆ—ã¨ã—ã¦é€ä¿¡ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸãŸã‚ã€
    # æ–‡å­—åˆ—ã®é…åˆ—ã‚¢ã‚¯ã‚»ã‚¹ (x[0]-x[1]-x[2]) ã‚’å‰Šé™¤ã—ã€to_datetimeã§ç›´æ¥ãƒ‘ãƒ¼ã‚¹ã™ã‚‹
    df_input['date'] = df_input['targetDate'].apply(lambda x: pd.to_datetime(x))
    
    base_date = df_input['date'].min()
    df_input['days_passed'] = (df_input['date'] - base_date).dt.days

    X = df_input[['days_passed']]
    y = df_input['condition']
    
    model = LinearRegression()
    model.fit(X, y)

    last_date = df_input['date'].max()
    future_dates = [last_date + datetime.timedelta(days=i) for i in range(1, 8)]
    
    future_days_passed = [(d - base_date).days for d in future_dates]
    future_X = pd.DataFrame({'days_passed': future_days_passed})

    predictions = model.predict(future_X)
    
    final_results = []
    for date, score in zip(future_dates, predictions):
        clipped_score = min(max(round(score, 2), 1.0), 7.0)
        final_results.append({
            "date": date.strftime('%Y-%m-%d'), 
            "predicted_score": clipped_score 
        })
    
    return final_results


# --- äºˆæ¸¬ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè¡Œé–¢æ•° ---
def run_prediction_service():
    print(f"ğŸš€ AI Engine Starting... Connecting to Kafka at {KAFKA_BROKER}")
    
    consumer = KafkaConsumer(
        KAFKA_TOPIC_INPUT,
        bootstrap_servers=KAFKA_BROKER,
        value_deserializer=lambda x: json.loads(x.decode('utf-8')),
        auto_offset_reset='latest',
        group_id='ai-engine-group'
    )
    producer = KafkaProducer(
        bootstrap_servers=KAFKA_BROKER,
        value_serializer=lambda x: json.dumps(x).encode('utf-8')
    )

    print("âœ… Connected to Kafka! Waiting for messages...")

    for message in consumer:
        try:
            print(f"\nğŸ“© Message Received! (Offset: {message.offset})")
            payload = message.value
            
            # 'history' ã‚­ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹å‡¦ç†
            history_data = payload.get('history', []) 
            
            if not history_data or not isinstance(history_data, list):
                print("âš ï¸ Invalid or empty data received (Expected a list of scores under 'history').")
                continue

            # DataFrameã«å¤‰æ›ã—ã€äºˆæ¸¬ã‚’å®Ÿè¡Œ
            df = pd.DataFrame(history_data)
            print("ğŸ§  Starting Prediction Analysis...")
            prediction_results = predict_weekly_condition(df)

            if prediction_results:
                # çµæœã‚’Dictã§ãƒ©ãƒƒãƒ—ã—ã¦è¿”é€ (messageIdã‚’å«ã‚ã‚‹)
                response = {
                    "messageId": payload.get("messageId"),
                    "predictions": prediction_results 
                }
                
                producer.send(KAFKA_TOPIC_OUTPUT, value=response)
                producer.flush()
                print(f"ğŸ“¤ Prediction done! Sent {len(prediction_results)} results to topic '{KAFKA_TOPIC_OUTPUT}'")
            else:
                print("âš ï¸ Prediction skipped. No results sent.")

        except Exception as e:
            print(f"âŒ Error processing message: {e}")

if __name__ == "__main__":
    run_prediction_service()